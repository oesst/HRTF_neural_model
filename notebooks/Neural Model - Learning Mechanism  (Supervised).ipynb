{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Model - Learning Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:60% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:60% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we present a first implementation of a neural model for sound source elevation estimation based on the computational HRTF model. \n",
    "\n",
    "**TODO**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from pathlib import Path\n",
    "from src.data import generateData\n",
    "from src.features import helpers as hp\n",
    "from src.visualization import helpers as hpVis\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from scipy.ndimage import gaussian_filter1d,convolve1d\n",
    "from scipy.signal import convolve2d\n",
    "from IPython import display\n",
    "from scipy.spatial import distance\n",
    "\n",
    "hpVis.set_layout(15)\n",
    "\n",
    "\n",
    "ROOT = Path(os.getcwd()).resolve().parents[0]\n",
    "\n",
    "SOUND_FILES = ROOT / 'data/raw/sound_samples/'\n",
    "# create a list of the sound files\n",
    "SOUND_FILES = list(SOUND_FILES.glob('**/*.wav'))\n",
    "\n",
    "\n",
    "class LinearReg():\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "\n",
    "        self.lr_model = LinearRegression()\n",
    "\n",
    "        self.x = x.reshape(-1, 1)\n",
    "        self.y = y.reshape(-1, 1)\n",
    "\n",
    "        self.lr_model.fit(self.x, self.y)\n",
    "\n",
    "        self.rr = self.lr_model.score(self.x, self.y)\n",
    "\n",
    "    def get_fitted_line(self):\n",
    "        return [self.x, self.lr_model.predict(self.x)]\n",
    "\n",
    "    def get_coefficients(self):\n",
    "        return self.lr_model.coef_[0, 0], self.lr_model.intercept_[0]\n",
    "\n",
    "    def get_score(self, x=0, y=0):\n",
    "        if x == 0 or y == 0:\n",
    "            return self.rr\n",
    "        else:\n",
    "            return self.lr_model.score(x, y)\n",
    "\n",
    "    def print_coefficients(self):\n",
    "        print('Gain: {0:1.2f}, Bias: {1:1.2f}, , r^2: {2:1.2f}'.format(self.lr_model.coef_[0, 0], self.lr_model.intercept_[0], self.rr))\n",
    "        return ('Gain: {0:1.2f},\\nBias: {1:1.2f},\\n' + r'$r^2$: {2:1.2f}').format(self.lr_model.coef_[0, 0], self.lr_model.intercept_[0], self.rr)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "#                  Simulation functions                    #\n",
    "############################################################\n",
    "\n",
    "tau = 0.005\n",
    "\n",
    "# Defines the output transfer function of q_A_SC \n",
    "def out_thres(q,threshold = 0.0,slope=1):    \n",
    "    return np.minimum(np.maximum((q-threshold)*slope,0),1)\n",
    "\n",
    "   \n",
    "# Defines the sigmoidal transfer function  \n",
    "def out_sigmoid(x,slope =5,operation_point=0.0):\n",
    "#     return 1 / (1 + np.exp(-(x-working_point)*slope) ) \n",
    "    tmp = (x-operation_point)*slope\n",
    "    return (2 / (1 + np.exp(-4*tmp**2)))-1\n",
    "\n",
    "\n",
    "#define a gauss function\n",
    "def gauss(x,mean,sigma):\n",
    "    if sigma == 0.0:\n",
    "        return np.zeros(x.shape)\n",
    "    else: \n",
    "        tmp = np.exp(-(x-mean)**2 /( 2 * sigma**2 ))\n",
    "        return tmp/np.max(tmp)\n",
    "    \n",
    "# define the ODE for inhibitory input neurons\n",
    "def ode_p_in(p ,excitatory_in):\n",
    " # tau defines how fast the membrane potential builds up\n",
    "#     tau = 1.0\n",
    "    # alpha defines the decay rate of the membrane potential but also the value to which it saturates (implicitly)\n",
    "    alpha=1\n",
    "    # beta defines the upper limit of the membrane potential\n",
    "    beta= 1\n",
    "    \n",
    "    # calculate the change of r_Alearn\n",
    "    d_p  = -alpha *p  + (beta -p )*excitatory_in\n",
    "    \n",
    "    return d_p /tau \n",
    "\n",
    "# define the ODE for gaussian filter neurons\n",
    "def ode_r_in(r,excitatory_in,inhibitory_in):\n",
    "    # tau defines how fast the membrane potential builds up\n",
    "#     tau = 1.0\n",
    "    # alpha defines the decay rate of the membrane potential but also the value to which it saturates (implicitly)\n",
    "    alpha= 1\n",
    "    # beta defines the upper limit of the membrane potential\n",
    "    beta= 200\n",
    "    # gamma defines the subtractive influence of the inhibitory input\n",
    "    gamma = 0.0\n",
    "    # kappa defines the divisive influence of the inhibitory input\n",
    "    kappa = 200\n",
    "    \n",
    "    # calculate the change of r_Alearn\n",
    "    d_r  = -alpha  * r * excitatory_in  + (beta -r ) * excitatory_in  - (gamma  + kappa  * r ) * inhibitory_in\n",
    "    \n",
    "    return d_r / tau\n",
    "\n",
    "\n",
    "# define the ODE for neuron p_sum\n",
    "def ode_p_sum(p ,excitatory_in):\n",
    " # tau defines how fast the membrane potential builds up\n",
    "#     tau = 1\n",
    "    # alpha defines the decay rate of the membrane potential but also the value to which it saturates (implicitly)\n",
    "    alpha= 1\n",
    "    # beta defines the upper limit of the membrane potential\n",
    "    beta= 1\n",
    "    \n",
    "    # calculate the change of r_Alearn\n",
    "    d_p  = -alpha *p  + (beta -p )*excitatory_in\n",
    "    \n",
    "    return d_p /tau \n",
    "\n",
    "# define the ODE for integration neurons\n",
    "def ode_r(r,excitatory_in,inhibitory_in=0):\n",
    "    # tau defines how fast the membrane potential builds up\n",
    "#     tau = 1\n",
    "    # alpha defines the decay rate of the membrane potential but also the value to which it saturates (implicitly)\n",
    "    alpha= 1\n",
    "    # beta defines the upper limit of the membrane potential\n",
    "    beta= 2\n",
    "    # gamma defines the subtractive influence of the inhibitory input\n",
    "    gamma = 0\n",
    "    # kappa defines the divisive influence of the inhibitory input\n",
    "    kappa = 1\n",
    "    \n",
    "    # calculate the change of r_Alearn\n",
    "    d_r  = -alpha  * r * excitatory_in   + (beta -r ) * excitatory_in  - (gamma  + kappa  * r ) * inhibitory_in\n",
    "    \n",
    "    return d_r /tau\n",
    "\n",
    "# define the ODE for read out neurons\n",
    "def ode_q_sum(q ,excitatory_in):\n",
    " # tau defines how fast the membrane potential builds up\n",
    "#     tau = 1\n",
    "    # alpha defines the decay rate of the membrane potential but also the value to which it saturates (implicitly)\n",
    "    alpha= 1\n",
    "    # beta defines the upper limit of the membrane potential\n",
    "    beta= 1\n",
    "    \n",
    "    # calculate the change of r_Alearn\n",
    "    d_q  = -alpha *q  + (beta -q )*excitatory_in\n",
    "    \n",
    "    return d_q /tau \n",
    "\n",
    "\n",
    "# # define the ODE for read out neurons\n",
    "# def ode_q_out(q ,excitatory_in):\n",
    "#  # tau defines how fast the membrane potential builds up\n",
    "# #     tau = 1\n",
    "#     # alpha defines the decay rate of the membrane potential but also the value to which it saturates (implicitly)\n",
    "#     alpha= 1\n",
    "#     # beta defines the upper limit of the membrane potential\n",
    "#     beta= 1\n",
    "    \n",
    "#     # calculate the change of r_Alearn\n",
    "#     d_q  = -alpha * q * excitatory_in  + (beta -q )*excitatory_in\n",
    "    \n",
    "#     return d_q /tau \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "######################## Set parameters ################################\n",
    "########################################################################\n",
    "azimuth = 12\n",
    "snr = 0.0\n",
    "freq_bands = 128\n",
    "participant_number = 8\n",
    "\n",
    "normalize = False\n",
    "time_window = 0.1  # time window in sec\n",
    "\n",
    "# filtering parameters\n",
    "normalization_type = 'sum_1'\n",
    "sigma_smoothing = 0\n",
    "sigma_gauss_norm = 1\n",
    "\n",
    "# use the mean subtracted map as the learned map\n",
    "mean_subtracted_map = True\n",
    "\n",
    "ear = 'ipsi'\n",
    "\n",
    "elevations = np.arange(0, 25, 1)\n",
    "\n",
    "\n",
    "############################################################\n",
    "#                  Simulation parameter                    #\n",
    "############################################################\n",
    "\n",
    "# Time step\n",
    "dt = 0.0001 # -> \n",
    "\n",
    "# Solve differential equation from time 0 to time T\n",
    "T = 0.3# \n",
    "# Descretize time into equal steps\n",
    "ts = np.linspace (0 , T , int ( T / dt )+1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sound No: 7 of 20.\n",
      "  -> Elevation : 97 of 25.\n",
      "  -> Time : 2500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-eac95b110dbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;31m# Works, but is supervised ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mr_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m  \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mv_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#generate inputs\n",
    "psd_all_c, psd_all_i = generateData.create_data(freq_bands, participant_number, snr, normalize, azimuth, time_window)\n",
    "\n",
    "# Take only given elevations\n",
    "input_c = psd_all_c[:, elevations, :]\n",
    "input_i = psd_all_i[:, elevations, :]\n",
    "\n",
    "# normalize inputs over frequencies\n",
    "input_c = input_c / input_c.sum(2)[:,:,np.newaxis]\n",
    "input_i = input_i / input_i.sum(2)[:,:,np.newaxis]\n",
    "\n",
    "# Define neurons\n",
    "# sound_types = np.array([0,4,6,9,10])\n",
    "sound_types = np.arange(0,20)\n",
    "# sound_types = np.array([0])\n",
    "\n",
    "n_sounds = len(sound_types)\n",
    "# elevations_angles = np.array([0])\n",
    "elevations_angles = np.arange(0,25,1)\n",
    "n_elevations = len(elevations_angles)\n",
    "\n",
    "sigma = 3\n",
    "\n",
    "\n",
    "r_steady = np.zeros((n_sounds,freq_bands,len(ts)-1))\n",
    "q_steady = np.zeros((n_sounds,len(elevations),len(ts)))\n",
    "\n",
    "x_kernel = np.arange(freq_bands)\n",
    "\n",
    "gauss_kernel = gauss(np.arange(-4*sigma,4*sigma),0,sigma)\n",
    "\n",
    "\n",
    "# weight initialization\n",
    "# w = np.zeros((freq_bands,elevations)) \n",
    "# w = np.random.random_sample((len(ts)*len(sound_types)*len(elevations_angles),len(elevations),freq_bands)) * 1\n",
    "w = np.random.random_sample((len(elevations),freq_bands)) * 0.1\n",
    "\n",
    "# time step for weights\n",
    "t_w = 0\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.00005\n",
    "\n",
    "trials = 150\n",
    "\n",
    "for i_sound,sound in enumerate(sound_types):\n",
    "#     for i_ele,ele in enumerate(elevations_angles):\n",
    "    for i_ele in range(trials):\n",
    "        \n",
    "        ele = np.random.randint(0,25)\n",
    "        sound = np.random.choice(sound_types)\n",
    "        \n",
    "        in_i = input_i[sound,ele]\n",
    "        in_c = input_c[sound,ele]\n",
    "\n",
    "        # since the input does not change over time. We can do this calculation ouside the loop\n",
    "        excitatory_in_p_i = convolve1d(out_thres(in_i),weights=gauss_kernel,axis=0,mode='reflect')\n",
    "        excitatory_in_p_c = convolve1d(out_thres(in_c),weights=gauss_kernel,axis=0,mode='reflect')\n",
    "        \n",
    "        # visual guidance signal TODO\n",
    "        v_in = np.zeros((len(elevations),1))\n",
    "        v_in[ele] = 1 \n",
    "        \n",
    "        p_in_c = np.zeros((len(ts),freq_bands))\n",
    "        p_in_i = np.zeros((len(ts),freq_bands))\n",
    "\n",
    "        r_in_c = np.zeros((len(ts),freq_bands))\n",
    "        r_in_i = np.zeros((len(ts),freq_bands))\n",
    "\n",
    "        p_sum_i = np.zeros((len(ts),freq_bands))\n",
    "        p_sum_c = np.zeros((len(ts),freq_bands))\n",
    "        r_ipsi = np.zeros((len(ts),freq_bands))\n",
    "        q_ele = np.zeros((len(ts),len(elevations)))\n",
    "\n",
    "\n",
    "        for t in range(0,len(ts)-1):\n",
    "            \n",
    "            \n",
    "            ## p_In_ipsi neuron\n",
    "            # feed inputs ipsi inhibition\n",
    "            p_in_i[t+1,:] = p_in_i[ t,:] + dt* ode_p_in(p_in_i[t,:],excitatory_in_p_i)  \n",
    "\n",
    "            ## r_In_ipsi neuron\n",
    "            excitatory_in = out_thres(in_i)\n",
    "            inhibitory_in = out_thres(p_in_i[ t,:])\n",
    "            r_in_i[ t+1,:] = r_in_i[t,:] + dt* ode_r_in(r_in_i[t,:],excitatory_in,inhibitory_in)   \n",
    "\n",
    "            ## p_In_contra neuron\n",
    "            # feed inputs ipsi inhibition\n",
    "            p_in_c[ t+1,:] = p_in_c[ t,:] + dt* ode_p_in(p_in_c[t,:],excitatory_in_p_c)  \n",
    "\n",
    "            ## r_In_contra neuron\n",
    "            excitatory_in = out_thres(in_c)\n",
    "            inhibitory_in = out_thres(p_in_c[ t,:])\n",
    "            r_in_c[t+1,:] = r_in_c[t,:] + dt* ode_r_in(r_in_c[t,:],excitatory_in,inhibitory_in)   \n",
    "\n",
    "            \n",
    "            ## p_sum neurons\n",
    "            excitatory_in = out_thres(r_in_i[ t,:]) \n",
    "            p_sum_i[ t+1,:] = p_sum_i[ t,:] + dt* ode_p_sum( p_sum_i[ t,:],excitatory_in)   \n",
    "            \n",
    "            excitatory_in = out_thres(r_in_c[ t,:]) \n",
    "            p_sum_c[ t+1,:] = p_sum_c[ t,:] + dt* ode_p_sum(p_sum_c[ t,:],excitatory_in)   \n",
    "            \n",
    "            \n",
    "            ## r_ipsi neuron\n",
    "            excitatory_in = out_thres(r_in_i[t,:])\n",
    "            inhibitory_in =  out_thres(p_sum_c[ t,:]) + out_thres(p_sum_i[ t,:])\n",
    "            r_ipsi[t+1,:] = r_ipsi[t,:] + dt* ode_r(r_ipsi[t,:],excitatory_in,inhibitory_in)   \n",
    "            \n",
    "            ## q readout neurons\n",
    "            excitatory_in = np.sum(r_ipsi[t,:] * w[:,:],axis=1)\n",
    "            q_ele[t+1,:] = q_ele[t,:]+ dt* ode_q_sum(q_ele[t,:],excitatory_in)   \n",
    "                      \n",
    "            \n",
    "            # Learning\n",
    "            q_ = q_ele[t,:,np.newaxis]\n",
    "            r_ = r_ipsi[t,:,np.newaxis]\n",
    "            v_ = v_in\n",
    "#             # Oja, does not really work with this stimuli presentation \n",
    "#             w[:,:] = w[:,:] + learning_rate * ( q_ * r_.T * v_ - q_**2 * w[:,:] )\n",
    "\n",
    "                # Works, but is supervised ...\n",
    "            w[:,:] = w[:,:] + learning_rate *  (r_.T -  w[:,:]) *v_\n",
    "            \n",
    "            if t%500 == 0:\n",
    "                clear_output(wait=True)\n",
    "                print('Sound No: '+str(i_sound+1)+' of '+str(n_sounds)+'.\\n  -> Elevation : '+str(i_ele+1)+' of '+str(n_elevations)+'.\\n  -> Time : '+str(t))   \n",
    "            \n",
    "    \n",
    "#         # store the output at time step -5\n",
    "#         r_steady[i_sound,i_ele,:] = r_ipsi\n",
    "#         q_steady[i_sound,i_ele,:] = q_ele\n",
    "\n",
    "\n",
    "    \n",
    "#     display.clear_output(wait=True)\n",
    "#     fig = plt.figure(figsize=(10,10))\n",
    "#     ax = fig.add_subplot(111)\n",
    "#     a = ax.pcolorfast(w)\n",
    "#     plt.colorbar(a)\n",
    "#                 fig = plt.figure(figsize=(10,10))\n",
    "#                 ax = fig.add_subplot(111)\n",
    "#                 plt.plot(h)\n",
    "\n",
    "#     print(ele,i_ele)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%notify\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.pcolormesh(w[:-1,:])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "# dill.dump_session('neural mode - learning mechanism testing')\n",
    "# # dill.dump_session('neural mode - learning mechanism - new normalization')\n",
    "# # dill.load_session('neural mode - learning mechanism - new normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Its important to normalize the weights. otherwise the learning is quite bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "tmp = w\n",
    "\n",
    "tmp = (tmp.T/ tmp.sum(1)).T #sum over all frequencies, result has len=25 that is to ensure equal energy in each elevation\n",
    "\n",
    "tmp = tmp / tmp.sum(0) # sum over all elevations, result has len=128 that is to ensure equal energy in each frequency band. needed for neural readout\n",
    "\n",
    "\n",
    "\n",
    "# tmp = tmp - np.mean(tmp,axis=0) # not sure if that does something.\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.pcolormesh(tmp)\n",
    "\n",
    "plt.colorbar()\n",
    "\n",
    "w_ =tmp\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate inputs\n",
    "psd_all_c, psd_all_i = generateData.create_data(freq_bands, participant_number, snr, normalize, azimuth, time_window)\n",
    "\n",
    "# Take only given elevations\n",
    "input_c = psd_all_c[:, elevations, :]\n",
    "input_i = psd_all_i[:, elevations, :]\n",
    "\n",
    "# normalize inputs over frequencies\n",
    "input_c = input_c / input_c.sum(2)[:,:,np.newaxis]\n",
    "input_i = input_i / input_i.sum(2)[:,:,np.newaxis]\n",
    "\n",
    "# Define neurons\n",
    "# sounds_types = np.array([0,4,6,9,10])\n",
    "sounds_types = np.arange(0,20)\n",
    "# sounds_types = np.array([0])\n",
    "\n",
    "n_sounds = len(sounds_types)\n",
    "# elevations_angles = np.array([0])\n",
    "elevations_angles = np.arange(0,25,1)\n",
    "n_elevations = len(elevations_angles)\n",
    "\n",
    "sigma = 3\n",
    "\n",
    "q = np.zeros((n_sounds,n_elevations,len(ts),len(elevations)))\n",
    "\n",
    "x_kernel = np.arange(freq_bands)\n",
    "\n",
    "gauss_kernel = gauss(np.arange(-4*sigma,4*sigma),0,sigma)\n",
    "\n",
    "results_bin = np.zeros((len(sounds_types),len(elevations_angles),3))\n",
    "\n",
    "for i_sound,sound in enumerate(sounds_types):\n",
    "    for i_ele,ele in enumerate(elevations_angles):\n",
    "\n",
    "        in_i = input_i[sound,ele]\n",
    "        in_c = input_c[sound,ele]\n",
    "\n",
    "        # since the input does not change over time. We can do this calculation ouside the loop\n",
    "        excitatory_in_p_i = convolve1d(out_thres(in_i),weights=gauss_kernel,axis=0,mode='reflect')\n",
    "        excitatory_in_p_c = convolve1d(out_thres(in_c),weights=gauss_kernel,axis=0,mode='reflect')\n",
    "        \n",
    "        p_in_c = np.zeros((len(ts),freq_bands))\n",
    "        p_in_i = np.zeros((len(ts),freq_bands))\n",
    "\n",
    "        r_in_c = np.zeros((len(ts),freq_bands))\n",
    "        r_in_i = np.zeros((len(ts),freq_bands))\n",
    "\n",
    "        p_sum_i = np.zeros((len(ts),freq_bands))\n",
    "        p_sum_c = np.zeros((len(ts),freq_bands))\n",
    "        r_ipsi = np.zeros((len(ts),freq_bands))\n",
    "        q_ele = np.zeros((len(ts),len(elevations)))\n",
    "                \n",
    "\n",
    "        for t in range(0,len(ts)-1):\n",
    "            \n",
    "            \n",
    "                        ## p_In_ipsi neuron\n",
    "            # feed inputs ipsi inhibition\n",
    "            p_in_i[ t+1,:] = p_in_i[ t,:] + dt* ode_p_in(p_in_i[t,:],excitatory_in_p_i)  \n",
    "\n",
    "            ## r_In_ipsi neuron\n",
    "            excitatory_in = out_thres(in_i)\n",
    "            inhibitory_in = out_thres(p_in_i[ t,:])\n",
    "            r_in_i[ t+1,:] = r_in_i[ t,:] + dt* ode_r_in(r_in_i[t,:],excitatory_in,inhibitory_in)   \n",
    "\n",
    "            ## p_In_contra neuron\n",
    "            # feed inputs ipsi inhibition\n",
    "            p_in_c[ t+1,:] = p_in_c[ t,:] + dt* ode_p_in(p_in_c[t,:],excitatory_in_p_c)  \n",
    "\n",
    "            ## r_In_contra neuron\n",
    "            excitatory_in = out_thres(in_c)\n",
    "            inhibitory_in = out_thres(p_in_c[ t,:])\n",
    "            r_in_c[ t+1,:] = r_in_c[ t,:] + dt* ode_r_in(r_in_c[t,:],excitatory_in,inhibitory_in)   \n",
    "\n",
    "            \n",
    "            ## p_sum neurons\n",
    "            excitatory_in = out_thres(r_in_i[ t,:]) \n",
    "            p_sum_i[ t+1,:] = p_sum_i[ t,:] + dt* ode_p_sum( p_sum_i[ t,:],excitatory_in)   \n",
    "            \n",
    "            excitatory_in = out_thres(r_in_c[ t,:]) \n",
    "            p_sum_c[ t+1,:] = p_sum_c[ t,:] + dt* ode_p_sum(p_sum_c[ t,:],excitatory_in)   \n",
    "            \n",
    "            \n",
    "            ## r_ipsi neuron\n",
    "            excitatory_in = out_thres(r_in_i[ t,:])\n",
    "            inhibitory_in =  out_thres(p_sum_c[ t,:]) + out_thres(p_sum_i[ t,:])\n",
    "            r_ipsi[ t+1,:] = r_ipsi[ t,:] + dt* ode_r(r_ipsi[t,:],excitatory_in,inhibitory_in)   \n",
    "            \n",
    "             ## q readout neurons\n",
    "            excitatory_in = np.dot(out_thres(r_ipsi[ t+1,:]), w_.T)\n",
    "            q_ele[t+1,:] = q_ele[t,:]+ dt* ode_q_sum(q_ele[t,:],excitatory_in)   \n",
    "\n",
    "            if t%2900 == 0:\n",
    "                clear_output(wait=True)\n",
    "                print('Sound No: '+str(i_sound+1)+' of '+str(n_sounds)+'.\\n  -> Elevation : '+str(i_ele+1)+' of '+str(n_elevations)+'.\\n  -> Time : '+str(t))        \n",
    "                \n",
    "        dists = distance.cdist(w_, (r_ipsi[ t,:,np.newaxis]).T, metric='correlation')\n",
    "        minimal_dist_ind = np.argmin(dists)\n",
    "#         print('Real elevation: '+str(ele))\n",
    "#         print('Correlation: '+str(minimal_dist_ind)+'  Neuron: '+ str(q[ -10,:].argmax()))\n",
    "#         print()\n",
    "#         plt.plot(q_ele[-1,:])\n",
    "#         plt.plot(excitatory_in)\n",
    "#         plt.show()\n",
    "        \n",
    "        ## save results\n",
    "        # real location\n",
    "        results_bin[i_sound,i_ele,0] = ele\n",
    "        # correlation\n",
    "        results_bin[i_sound,i_ele,1] = minimal_dist_ind\n",
    "        # neuron activation\n",
    "        results_bin[i_sound,i_ele,2] = q_ele[ -1,:].argmax()\n",
    "             \n",
    "#             if t%2950 == 0:\n",
    "\n",
    "#                 print('Neuron: '+ str(excitatory_in.argmax()))\n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%notify\n",
    "fig = plt.figure()\n",
    "\n",
    "axes = fig.subplots(1,2,squeeze=False,sharex=True,sharey=True)\n",
    "\n",
    "ax1 = axes[0,0]\n",
    "ax1.set_title('Correlation Results')\n",
    "for i_sound,sound in enumerate(sounds_types):\n",
    "    ax1.scatter(results_bin[i_sound,:,0],results_bin[i_sound,:,1])\n",
    "\n",
    "lr = LinearReg(np.squeeze(results_bin[:,:,0]),np.squeeze(results_bin[:,:,1]))\n",
    "x,y = lr.get_fitted_line()\n",
    "ax1.plot(x,y,linewidth = 3,color='black')\n",
    "print('Correlation:')\n",
    "lr.print_coefficients()\n",
    "ax1.set_ylim([0,25])\n",
    "ax1.set_xlim([0,25])\n",
    "\n",
    "ax1 = axes[0,1]\n",
    "ax1.set_title('Neuron Results')\n",
    "for i_sound,sound in enumerate(sounds_types):\n",
    "    ax1.scatter(results_bin[i_sound,:,0],results_bin[i_sound,:,2])\n",
    "    \n",
    "lr = LinearReg(np.squeeze(results_bin[:,:,0]),np.squeeze(results_bin[:,:,2]))\n",
    "x,y = lr.get_fitted_line()\n",
    "ax1.plot(x,y,linewidth = 3,color='black')\n",
    "print('Neuron:')\n",
    "lr.print_coefficients()\n",
    "# ax1.set_ylim([0,25])\n",
    "# ax1.set_xlim([0,25])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monaural Inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate inputs\n",
    "psd_all_c, psd_all_i = generateData.create_data(freq_bands, participant_number, snr, normalize, azimuth, time_window)\n",
    "\n",
    "# Take only given elevations\n",
    "input_c = psd_all_c[:, elevations, :]\n",
    "input_i = psd_all_i[:, elevations, :]\n",
    "\n",
    "# normalize inputs over frequencies\n",
    "input_c = input_c / input_c.sum(2)[:,:,np.newaxis]\n",
    "input_i = input_i / input_i.sum(2)[:,:,np.newaxis]\n",
    "\n",
    "# Define neurons\n",
    "# sounds_types = np.array([0,4,6,9,10])\n",
    "sounds_types = np.arange(0,20)\n",
    "# sounds_types = np.array([0])\n",
    "\n",
    "n_sounds = len(sounds_types)\n",
    "# elevations_angles = np.array([0])\n",
    "elevations_angles = np.arange(0,25,1)\n",
    "n_elevations = len(elevations_angles)\n",
    "\n",
    "sigma = 3\n",
    "\n",
    "q = np.zeros((n_sounds,n_elevations,len(ts),len(elevations)))\n",
    "\n",
    "x_kernel = np.arange(freq_bands)\n",
    "\n",
    "gauss_kernel = gauss(np.arange(-4*sigma,4*sigma),0,sigma)\n",
    "\n",
    "results_mono = np.zeros((len(sounds_types),len(elevations_angles),3))\n",
    "\n",
    "for i_sound,sound in enumerate(sounds_types):\n",
    "    for i_ele,ele in enumerate(elevations_angles):\n",
    "\n",
    "        in_i = input_i[sound,ele]\n",
    "        in_c = input_c[sound,ele]\n",
    "        \n",
    "        # Contralateral input is zero\n",
    "        in_c = np.ones(in_c.shape)*0.001\n",
    "\n",
    "        # since the input does not change over time. We can do this calculation ouside the loop\n",
    "        excitatory_in_p_i = convolve1d(out_thres(in_i),weights=gauss_kernel,axis=0,mode='reflect')\n",
    "        excitatory_in_p_c = convolve1d(out_thres(in_c),weights=gauss_kernel,axis=0,mode='reflect')\n",
    "        \n",
    "        p_in_c = np.zeros((len(ts),freq_bands))\n",
    "        p_in_i = np.zeros((len(ts),freq_bands))\n",
    "\n",
    "        r_in_c = np.zeros((len(ts),freq_bands))\n",
    "        r_in_i = np.zeros((len(ts),freq_bands))\n",
    "\n",
    "        p_sum_i = np.zeros((len(ts),freq_bands))\n",
    "        p_sum_c = np.zeros((len(ts),freq_bands))\n",
    "        r_ipsi = np.zeros((len(ts),freq_bands))\n",
    "        q_ele = np.zeros((len(ts),len(elevations)))\n",
    "                \n",
    "\n",
    "        for t in range(0,len(ts)-1):\n",
    "            \n",
    "            \n",
    "                        ## p_In_ipsi neuron\n",
    "            # feed inputs ipsi inhibition\n",
    "            p_in_i[ t+1,:] = p_in_i[ t,:] + dt* ode_p_in(p_in_i[t,:],excitatory_in_p_i)  \n",
    "\n",
    "            ## r_In_ipsi neuron\n",
    "            excitatory_in = out_thres(in_i)\n",
    "            inhibitory_in = out_thres(p_in_i[ t,:])\n",
    "            r_in_i[ t+1,:] = r_in_i[ t,:] + dt* ode_r_in(r_in_i[t,:],excitatory_in,inhibitory_in)   \n",
    "\n",
    "            ## p_In_contra neuron\n",
    "            # feed inputs ipsi inhibition\n",
    "            p_in_c[ t+1,:] = p_in_c[ t,:] + dt* ode_p_in(p_in_c[t,:],excitatory_in_p_c)  \n",
    "\n",
    "            ## r_In_contra neuron\n",
    "            excitatory_in = out_thres(in_c)\n",
    "            inhibitory_in = out_thres(p_in_c[ t,:])\n",
    "            r_in_c[ t+1,:] = r_in_c[ t,:] + dt* ode_r_in(r_in_c[t,:],excitatory_in,inhibitory_in)   \n",
    "\n",
    "            \n",
    "            ## p_sum neurons\n",
    "            excitatory_in = out_thres(r_in_i[ t,:]) \n",
    "            p_sum_i[ t+1,:] = p_sum_i[ t,:] + dt* ode_p_sum( p_sum_i[ t,:],excitatory_in)   \n",
    "            \n",
    "            excitatory_in = out_thres(r_in_c[ t,:]) \n",
    "            p_sum_c[ t+1,:] = p_sum_c[ t,:] + dt* ode_p_sum(p_sum_c[ t,:],excitatory_in)   \n",
    "            \n",
    "            \n",
    "            ## r_ipsi neuron\n",
    "            excitatory_in = out_thres(r_in_i[ t,:])\n",
    "            inhibitory_in =  out_thres(p_sum_c[ t,:]) + out_thres(p_sum_i[ t,:]) #<-- not necessary\n",
    "            r_ipsi[ t+1,:] = r_ipsi[ t,:] + dt* ode_r(r_ipsi[t,:],excitatory_in,inhibitory_in)   \n",
    "            \n",
    "             ## q readout neurons\n",
    "            excitatory_in = np.dot(out_thres(r_ipsi[ t+1,:]), w_.T)\n",
    "            q_ele[t+1,:] = q_ele[t,:]+ dt* ode_q_sum(q_ele[t,:],excitatory_in)   \n",
    "            if t%2900 == 0:\n",
    "                clear_output(wait=True)\n",
    "                print('Sound No: '+str(i_sound+1)+' of '+str(n_sounds)+'.\\n  -> Elevation : '+str(i_ele+1)+' of '+str(n_elevations)+'.\\n  -> Time : '+str(t))        \n",
    "                \n",
    "        dists = distance.cdist(w_, (r_ipsi[ t,:,np.newaxis]).T, metric='correlation')\n",
    "        minimal_dist_ind = np.argmin(dists)\n",
    "\n",
    "        \n",
    "#         clear_output(wait=True)\n",
    "\n",
    "#         plt.figure(figsize=(5,5))\n",
    "        \n",
    "# #         plt.plot(r_ipsi[-1,:])\n",
    "#         plt.plot(q_ele[-1,:])\n",
    "# #         plt.plot(excitatory_in)\n",
    "# #         plt.ylim([0.7,0.8])\n",
    "#         plt.show()\n",
    "\n",
    "        ## save results\n",
    "        # real location\n",
    "        results_mono[i_sound,i_ele,0] = ele\n",
    "        # correlation\n",
    "        results_mono[i_sound,i_ele,1] = minimal_dist_ind\n",
    "        # neuron activation\n",
    "        results_mono[i_sound,i_ele,2] = q_ele[ -1,:].argmax()\n",
    "             \n",
    "\n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%notify\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "axes = fig.subplots(1,2,squeeze=False,sharex=True,sharey=True)\n",
    "\n",
    "ax1 = axes[0,0]\n",
    "ax1.set_title('Correlation Results')\n",
    "for i_sound,sound in enumerate(sounds_types):\n",
    "    ax1.scatter(results_mono[i_sound,:,0],results_mono[i_sound,:,1])\n",
    "\n",
    "lr = LinearReg(np.squeeze(results_mono[:,:,0]),np.squeeze(results_mono[:,:,1]))\n",
    "x,y = lr.get_fitted_line()\n",
    "ax1.plot(x,y,linewidth = 3,color='black')\n",
    "print('Correlation:')\n",
    "lr.print_coefficients()\n",
    "ax1.set_ylim([0,25])\n",
    "ax1.set_xlim([0,25])\n",
    "\n",
    "ax1 = axes[0,1]\n",
    "ax1.set_title('Neuron Results')\n",
    "for i_sound,sound in enumerate(sounds_types):\n",
    "    ax1.scatter(results_mono[i_sound,:,0],results_mono[i_sound,:,2])\n",
    "    \n",
    "lr = LinearReg(np.squeeze(results_mono[:,:,0]),np.squeeze(results_mono[:,:,2]))\n",
    "x,y = lr.get_fitted_line()\n",
    "ax1.plot(x,y,linewidth = 3,color='black')\n",
    "print('Neuron:')\n",
    "lr.print_coefficients()\n",
    "# ax1.set_ylim([0,25])\n",
    "# ax1.set_xlim([0,25])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the values\n",
    "\n",
    "x_test_bin,y_test_bin = scale_v(results_bin[:,:,0],results_bin[:,:,2],25)\n",
    "x_test_mono,y_test_mono = scale_v(results_mono[:,:,0],results_mono[:,:,2],25)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "axes = fig.subplots(1,2,squeeze=False,sharex=True,sharey=True)\n",
    "\n",
    "ax1 = axes[0,0]\n",
    "ax1.set_title('Monaural')\n",
    "for i_sound,sound in enumerate(sounds_types):\n",
    "    ax1.scatter(x_test_mono[i_sound,:],y_test_mono[i_sound,:])\n",
    "    \n",
    "lr = LinearReg(np.squeeze(x_test_mono),np.squeeze(y_test_mono))\n",
    "x,y = lr.get_fitted_line()\n",
    "ax1.plot(x,y,linewidth = 3,color='black')\n",
    "print('Monaural:')\n",
    "text_str = lr.print_coefficients()\n",
    "# these are matplotlib.patch.Patch properties\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    "\n",
    "# place a text box in upper left in axes coords\n",
    "ax1.text(0.05, 0.95, text_str, transform=ax1.transAxes, verticalalignment='top', bbox=props)\n",
    "\n",
    "t = np.zeros(6)\n",
    "t[0] = -55\n",
    "t[1] = -45\n",
    "t[2] = 0\n",
    "t[3] = 45\n",
    "t[4] = 90\n",
    "t[5] = 100\n",
    "ax1.set_xticks(t[1:-1])\n",
    "ax1.set_yticks(t[1:-1])\n",
    "\n",
    "ax1.set_ylabel('Estimated Elevation [deg]')\n",
    "ax1.set_xlabel('True Elevation [deg]')\n",
    "\n",
    "\n",
    "ax1 = axes[0,1]\n",
    "ax1.set_title('Binaural')\n",
    "for i_sound,sound in enumerate(sounds_types):\n",
    "    ax1.scatter(x_test_bin[i_sound,:],y_test_bin[i_sound,:])\n",
    "    \n",
    "lr = LinearReg(np.squeeze(x_test_bin[:,:]),np.squeeze(y_test_bin[:,:]))\n",
    "x,y = lr.get_fitted_line()\n",
    "ax1.plot(x,y,linewidth = 3,color='black')\n",
    "print('Binaural:')\n",
    "\n",
    "text_str = lr.print_coefficients()\n",
    "# these are matplotlib.patch.Patch properties\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    "\n",
    "# place a text box in upper left in axes coords\n",
    "ax1.text(0.05, 0.95, text_str, transform=ax1.transAxes, verticalalignment='top', bbox=props)\n",
    "\n",
    "# ax1.set_ylim([0,25])\n",
    "# ax1.set_xlim([0,25])\n",
    "\n",
    "\n",
    "\n",
    "ax1.set_xlabel('True Elevation [deg]')\n",
    "\n",
    "ax1.set_xticks(t[1:-1])\n",
    "\n",
    "\n",
    "plt.savefig(\"neuron_results_correlation.pdf\", dpi=300)\n",
    "plt.savefig(\"neuron_results_correlation.svg\", dpi=300)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_v(x_test, y_test, n_elevations):\n",
    "    a = x_test /  n_elevations\n",
    "    a = a * (n_elevations - 1) * 5.625 - 45\n",
    "    x_test = a\n",
    "\n",
    "    a = y_test /  n_elevations\n",
    "    a = a * (n_elevations - 1) * 5.625 - 45\n",
    "    y_test = a\n",
    "\n",
    "    return x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
